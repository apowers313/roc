{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[nvidia cuda python learning](https://github.com/apowers313/roc/blob/master/experiments/2024.09.02-17.58.36-nvidia-cuda-python-learning/2024.09.02-17.58.36-nvidia-cuda-python-learning.ipynb)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save notebook path before we get started\n",
    "import os\n",
    "\n",
    "notebook_path = os.path.abspath(\"\") # not sure if this or os.getcwd() is more reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baracuda import CudaDevice\n",
    "\n",
    "print(\"Device Count:\", CudaDevice.count())\n",
    "\n",
    "dev = CudaDevice(0)\n",
    "print(\"Device Name:\", dev.name)\n",
    "print(\"Compute Capability:\", dev.compute_capability)\n",
    "print(\"Driver Version:\", dev.driver_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dumb Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "creating context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "#include \"test.h\"\n",
      "\n",
      "__global__ void test_kernel() {\n",
      "  printf(\"(%d, %d, %d): Block (%d, %d, %d), Thread (%d, %d, %d) -- %d\\n\", MY_X,\n",
      "         MY_Y, MY_Z, blockIdx.x, blockIdx.y, blockIdx.z, threadIdx.x,\n",
      "         threadIdx.y, threadIdx.z, MY_THING);\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "Calling function: test_kernel\n",
      "getting default context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0): Block (0, 0, 0), Thread (0, 0, 0) -- 42\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile\n",
    "\n",
    "mod = CudaSourceFile(\"test_kernel.cu\")\n",
    "mod.call(\"test_kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments\n",
    "\n",
    "From example code:\n",
    "\n",
    "---\n",
    "\n",
    "https://nvidia.github.io/cuda-python/overview.html#\n",
    "\n",
    "``` python\n",
    "NUM_THREADS = 512  # Threads per block\n",
    "NUM_BLOCKS = 32768  # Blocks per grid\n",
    "\n",
    "a = np.array([2.0], dtype=np.float32)\n",
    "n = np.array(NUM_THREADS * NUM_BLOCKS, dtype=np.uint32)\n",
    "bufferSize = n * a.itemsize\n",
    "\n",
    "hX = np.random.rand(n).astype(dtype=np.float32)\n",
    "hY = np.random.rand(n).astype(dtype=np.float32)\n",
    "hOut = np.zeros(n).astype(dtype=np.float32)\n",
    "\n",
    "dXclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "dYclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "dOutclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "\n",
    "stream = checkCudaErrors(cuda.cuStreamCreate(0))\n",
    "\n",
    "checkCudaErrors(cuda.cuMemcpyHtoDAsync(dXclass, hX.ctypes.data, bufferSize, stream))\n",
    "checkCudaErrors(cuda.cuMemcpyHtoDAsync(dYclass, hY.ctypes.data, bufferSize, stream))\n",
    "\n",
    "# The following code example is not intuitive\n",
    "# Subject to change in a future release\n",
    "dX = np.array([int(dXclass)], dtype=np.uint64)\n",
    "dY = np.array([int(dYclass)], dtype=np.uint64)\n",
    "dOut = np.array([int(dOutclass)], dtype=np.uint64)\n",
    "\n",
    "args = [a, dX, dY, dOut, n]\n",
    "args = np.array([arg.ctypes.data for arg in args], dtype=np.uint64)\n",
    "\n",
    "checkCudaErrors(\n",
    "    cuda.cuLaunchKernel(\n",
    "        kernel,\n",
    "        NUM_BLOCKS,  # grid x dim\n",
    "        1,  # grid y dim\n",
    "        1,  # grid z dim\n",
    "        NUM_THREADS,  # block x dim\n",
    "        1,  # block y dim\n",
    "        1,  # block z dim\n",
    "        0,  # dynamic shared memory\n",
    "        stream,  # stream\n",
    "        args.ctypes.data,  # kernel arguments\n",
    "        0,  # extra (ignore)\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "or:\n",
    "\n",
    "https://github.com/NVIDIA/cuda-python/blob/main/examples/3_CUDA_Features/simpleCudaGraphs_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "creating context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void simple(int n) {\n",
      "  printf(\"simple args:\\n\");\n",
      "  printf(\"arg: %d\\n\", n);\n",
      "  printf(\"simple args done.\\n\");\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "Calling function: simple\n",
      "getting default context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple args:\n",
      "arg: 1234\n",
      "simple args done.\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaData\n",
    "import ctypes\n",
    "\n",
    "mod = CudaSourceFile(\"simple_args.cu\")\n",
    "mod.call(\"simple\", CudaData(1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "creating context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void k1() {\n",
      "  printf(\"kernel 1 starting...\\n\");\n",
      "  // cudaEvent_t e;\n",
      "  // cudaEventCreateWithFlags(&e, cudaEventDisableTiming);\n",
      "  printf(\"kernel 1 done.\\n\");\n",
      "}\n",
      "\n",
      "__global__ void k2() {\n",
      "  printf(\"kernel 2 starting...\\n\");\n",
      "  printf(\"kernel 2 done.\\n\");\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "getting default context\n",
      "Num of nodes in the graph created manually = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel 2 starting...\n",
      "kernel 1 starting...\n",
      "kernel 2 done.\n",
      "kernel 1 done.\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaGraph\n",
    "\n",
    "mod = CudaSourceFile(\"daisy_chain.cu\")\n",
    "g = CudaGraph()\n",
    "k1 = mod.get_function(\"k1\")\n",
    "k2 = mod.get_function(\"k2\")\n",
    "g.add_kernel_node(k1)\n",
    "g.add_kernel_node(k2)\n",
    "nodes = g.nodes\n",
    "print(f\"Num of nodes in the graph created manually = {len(nodes)}\")\n",
    "g.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
