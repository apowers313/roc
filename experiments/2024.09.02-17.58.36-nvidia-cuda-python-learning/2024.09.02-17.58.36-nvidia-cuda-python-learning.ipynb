{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[nvidia cuda python learning](https://github.com/apowers313/roc/blob/master/experiments/2024.09.02-17.58.36-nvidia-cuda-python-learning/2024.09.02-17.58.36-nvidia-cuda-python-learning.ipynb)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep  4 17:33:20 PDT 2024\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save notebook path before we get started\n",
    "import os\n",
    "\n",
    "notebook_path = os.path.abspath(\"\") # not sure if this or os.getcwd() is more reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep  4 23:54:40 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   39C    P8              2W /  220W |       2MiB /  12282MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Count: 1\n",
      "Device Name: NVIDIA GeForce RTX 4070 SUPER\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "Compute Capability: (8, 9)\n",
      "Driver Version: (12, 4)\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaDevice\n",
    "\n",
    "print(\"Device Count:\", CudaDevice.count())\n",
    "\n",
    "dev = CudaDevice(0)\n",
    "print(\"Device Name:\", dev.name)\n",
    "print(\"Compute Capability:\", dev.compute_capability)\n",
    "print(\"Driver Version:\", dev.driver_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dumb Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "creating context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "#include \"test.h\"\n",
      "\n",
      "__global__ void test_kernel() {\n",
      "  printf(\"(%d, %d, %d): Block (%d, %d, %d), Thread (%d, %d, %d) -- %d\\n\", MY_X,\n",
      "         MY_Y, MY_Z, blockIdx.x, blockIdx.y, blockIdx.z, threadIdx.x,\n",
      "         threadIdx.y, threadIdx.z, MY_THING);\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "Calling function: test_kernel\n",
      "getting default context\n",
      "nv_args 0\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile\n",
    "\n",
    "mod = CudaSourceFile(\"test_kernel.cu\")\n",
    "mod.call(\"test_kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baracuda.CudaMemory at 0x7fbcad0c3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from baracuda import CudaMemory\n",
    "\n",
    "CudaMemory(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments\n",
    "\n",
    "From example code:\n",
    "\n",
    "---\n",
    "\n",
    "https://nvidia.github.io/cuda-python/overview.html#\n",
    "\n",
    "``` python\n",
    "NUM_THREADS = 512  # Threads per block\n",
    "NUM_BLOCKS = 32768  # Blocks per grid\n",
    "\n",
    "a = np.array([2.0], dtype=np.float32)\n",
    "n = np.array(NUM_THREADS * NUM_BLOCKS, dtype=np.uint32)\n",
    "bufferSize = n * a.itemsize\n",
    "\n",
    "hX = np.random.rand(n).astype(dtype=np.float32)\n",
    "hY = np.random.rand(n).astype(dtype=np.float32)\n",
    "hOut = np.zeros(n).astype(dtype=np.float32)\n",
    "\n",
    "dXclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "dYclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "dOutclass = checkCudaErrors(cuda.cuMemAlloc(bufferSize))\n",
    "\n",
    "stream = checkCudaErrors(cuda.cuStreamCreate(0))\n",
    "\n",
    "checkCudaErrors(cuda.cuMemcpyHtoDAsync(dXclass, hX.ctypes.data, bufferSize, stream))\n",
    "checkCudaErrors(cuda.cuMemcpyHtoDAsync(dYclass, hY.ctypes.data, bufferSize, stream))\n",
    "\n",
    "# The following code example is not intuitive\n",
    "# Subject to change in a future release\n",
    "dX = np.array([int(dXclass)], dtype=np.uint64)\n",
    "dY = np.array([int(dYclass)], dtype=np.uint64)\n",
    "dOut = np.array([int(dOutclass)], dtype=np.uint64)\n",
    "\n",
    "args = [a, dX, dY, dOut, n]\n",
    "args = np.array([arg.ctypes.data for arg in args], dtype=np.uint64)\n",
    "\n",
    "checkCudaErrors(\n",
    "    cuda.cuLaunchKernel(\n",
    "        kernel,\n",
    "        NUM_BLOCKS,  # grid x dim\n",
    "        1,  # grid y dim\n",
    "        1,  # grid z dim\n",
    "        NUM_THREADS,  # block x dim\n",
    "        1,  # block y dim\n",
    "        1,  # block z dim\n",
    "        0,  # dynamic shared memory\n",
    "        stream,  # stream\n",
    "        args.ctypes.data,  # kernel arguments\n",
    "        0,  # extra (ignore)\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "or:\n",
    "\n",
    "https://github.com/NVIDIA/cuda-python/blob/main/examples/3_CUDA_Features/simpleCudaGraphs_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void simple(int n) {\n",
      "  printf(\"simple args:\\n\");\n",
      "  printf(\"arg: %d\\n\", n);\n",
      "  printf(\"simple args done.\\n\");\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "(0, 0, 0): Block (0, 0, 0), Thread (0, 0, 0) -- 42\n",
      "Compilation results\u0000\n",
      "Calling function: simple\n",
      "getting default context\n",
      "nv_args ((1234,), (<class 'ctypes.c_uint'>,))\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaData\n",
    "import ctypes\n",
    "\n",
    "mod = CudaSourceFile(\"simple_args.cu\")\n",
    "mod.call(\"simple\", CudaData(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void print_buf(char *buf, int len) {\n",
      "  int i;\n",
      "\n",
      "  printf(\"buf is %p\\n\", buf);\n",
      "  printf(\"len is %d\\n\", len);\n",
      "  printf(\"buf[0] is %d\\n\", buf[0]);\n",
      "\n",
      "  for (i = 0; i < len; i++) {\n",
      "    printf(\"buf: %d\\n\", buf[i]);\n",
      "  }\n",
      "  printf(\"buf as string: %s\\n\", buf);\n",
      "  printf(\"done.\\n\");\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "mem hex 0x7fbc71e00e00\n",
      "Calling function: print_buf\n",
      "getting default context\n",
      "nv_args ((140447341088256, 10), (<class 'ctypes.c_void_p'>, <class 'ctypes.c_uint'>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buf is 0x7fbc71e00e00\n",
      "len is 10\n",
      "buf[0] is 104\n",
      "buf: 104\n",
      "buf: 105\n",
      "buf: 32\n",
      "buf: 116\n",
      "buf: 104\n",
      "buf: 101\n",
      "buf: 114\n",
      "buf: 101\n",
      "buf: 46\n",
      "buf: 0\n",
      "buf as string: hi there.\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaData, CudaMemory\n",
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "mod = CudaSourceFile(\"print_buf.cu\")\n",
    "str = bytearray(b\"hi there.\")\n",
    "str.append(0)\n",
    "arr = np.array(str, dtype=np.uint8)\n",
    "mem = CudaMemory.from_np(arr)\n",
    "print(\"mem hex\", hex(mem.nv_memory))\n",
    "mod.call(\"print_buf\", [CudaData(mem), CudaData(mem.size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CudaSource.__del__ at 0x7f7c218cb380>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apowers/Projects/roc/experiments/2024.09.02-17.58.36-nvidia-cuda-python-learning/baracuda.py\", line 514, in __del__\n",
      "    checkCudaErrors(cuda.cuModuleUnload(self.nv_module))\n",
      "                                        ^^^^^^^^^^^^^^\n",
      "AttributeError: 'CudaSourceFile' object has no attribute 'nv_module'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void k1() {\n",
      "  printf(\"kernel 1 starting...\\n\");\n",
      "  printf(\"kernel 1 done.\\n\");\n",
      "}\n",
      "\n",
      "__global__ void k2() {\n",
      "  printf(\"kernel 2 starting...\\n\");\n",
      "  printf(\"kernel 2 done.\\n\");\n",
      "}\n",
      "\n",
      "__global__ void k3(int n) {\n",
      "  printf(\"kernel 3 starting...\\n\");\n",
      "  printf(\"kernel 3 arg: %d\", n);\n",
      "  printf(\"kernel 3 done.\\n\");\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "getting default context\n",
      "Num of nodes in the graph created manually = 2\n",
      "Num of nodes in the graph created manually = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel 2 starting...\n",
      "kernel 1 starting...\n",
      "kernel 2 done.\n",
      "kernel 1 done.\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaGraph, KernelNode\n",
    "\n",
    "mod = CudaSourceFile(\"daisy_chain.cu\")\n",
    "g = CudaGraph()\n",
    "k1 = mod.get_function(\"k1\")\n",
    "k2 = mod.get_function(\"k2\")\n",
    "g.add_node(KernelNode(k1))\n",
    "g.add_node(KernelNode(k2))\n",
    "\n",
    "print(f\"Num of nodes in the graph created manually = {len(g.nodes)}\")\n",
    "print(f\"Num of nodes in the graph created manually = {len(g.nv_nodes)}\")\n",
    "g.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting default context\n",
      "CODE:\n",
      "-------\n",
      "extern \"C\" {\n",
      "__global__ void print_buf(char *buf, int len) {\n",
      "  int i;\n",
      "\n",
      "  printf(\"buf is %p\\n\", buf);\n",
      "  printf(\"len is %d\\n\", len);\n",
      "  printf(\"buf[0] is %d\\n\", buf[0]);\n",
      "\n",
      "  for (i = 0; i < len; i++) {\n",
      "    printf(\"buf: %d\\n\", buf[i]);\n",
      "  }\n",
      "  printf(\"buf as string: %s\\n\", buf);\n",
      "  printf(\"done.\\n\");\n",
      "}\n",
      "}\n",
      "\n",
      "-------\n",
      "\n",
      "Compilation results\u0000\n",
      "getting default context\n",
      "getting default context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buf is 0x7f216f800200\n",
      "len is 4\n",
      "buf[0] is 42\n",
      "buf: 42\n",
      "buf: 42\n",
      "buf: 42\n",
      "buf: 42\n",
      "buf as string: ****\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from baracuda import CudaSourceFile, CudaData, CudaMemory, MemsetNode, KernelNode, CudaDevice, CudaGraph\n",
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mod = CudaSourceFile(\"print_buf.cu\")\n",
    "fn = mod.get_function(\"print_buf\")\n",
    "\n",
    "mem = CudaMemory(4)\n",
    "# str = bytearray(b\"hi there.\")\n",
    "# str.append(0)\n",
    "# arr = np.array(str, dtype=np.uint8)\n",
    "# mem = CudaMemory.from_np(arr)\n",
    "# print(\"mem hex:\", hex(mem.nv_memory))\n",
    "\n",
    "g = CudaGraph()\n",
    "g.add_node(MemsetNode(mem, 42, mem.size))\n",
    "# TODO: add dependency\n",
    "g.add_node(KernelNode(fn, [CudaData(mem), CudaData(mem.size)]))\n",
    "g.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
